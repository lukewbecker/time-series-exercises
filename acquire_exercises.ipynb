{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the os library specifically for reading the csv once I've created the file in my working directory.\n",
    "import os\n",
    "\n",
    "# web-based requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"api\":\"/api/v1\",\"help\":\"/documentation\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://python.zach.lol'\n",
    "print(requests.get(base_url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The API accepts GET requests for all endpoints, where endpoints are prefixed\n",
      "with\n",
      "\n",
      "    /api/{version}\n",
      "\n",
      "Where version is \"v1\"\n",
      "\n",
      "Valid endpoints:\n",
      "\n",
      "- /stores[/{store_id}]\n",
      "- /items[/{item_id}]\n",
      "- /sales[/{sale_id}]\n",
      "\n",
      "All endpoints accept a `page` parameter that can be used to navigate through\n",
      "the results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(base_url + '/documentation')\n",
    "print(response.json()['payload'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I have the info I need to start getting specific portions of the information via the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using the code from the lesson as a guide, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['payload', 'status'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "\n",
    "data = response.json()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['payload']['items'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I need to go back and recall how to work with dictionaries. I need to use those techniques to parse the info, instead of trying to use API to prep the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from page 1\n",
    "\n",
    "items = pd.DataFrame(data['payload']['items'])\n",
    "print(items.shape)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url + data['payload']['next_page'])\n",
    "data = response.json()\n",
    "\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])\n",
    "\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url + data['payload']['next_page'])\n",
    "data = response.json()\n",
    "\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])\n",
    "\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(columns = ['level_0', 'index'], inplace = True)\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.DataFrame(data['payload']['items'])\n",
    "print(items_df.shape)\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to try creating an if loop for this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload']['max_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_test = requests.get('https://python.zach.lol/api/v1/items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_test = requests.get(base_url + data_test['payload']['next_page'])\n",
    "data_test = response_test.json()\n",
    "print(data_test['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_test = requests.get(base_url + data_test['payload']['next_page'])\n",
    "data_test = response_test.json()\n",
    "print(data_test['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['payload']['max_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function:\n",
    "\n",
    "def get_items_new(base_url):\n",
    "    '''\n",
    "    This function is designed to get the items data from Zach's web service and turn that data into a pandas\n",
    "    dataframe for use.\n",
    "    '''\n",
    "    \n",
    "    # initialize:\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['payload']['items'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in range(0, data['payload']['max_page']):\n",
    "        response = requests.get(base_url + data['payload']['next_page'])\n",
    "        data = response.json()\n",
    "        df = pd.concat([df, pd.DataFrame(data['payload']['items'])], ignore_index = True)\n",
    "        if data['payload']['next_page'] == None:\n",
    "            return df\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://python.zach.lol'\n",
    "\n",
    "items_df_testing = get_items_new(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.shape, items_df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url + '/api/v1/stores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do the same thing, but for stores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['payload', 'status'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_stores = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "\n",
    "data_stores = response_stores.json()\n",
    "data_stores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max_page', 'next_page', 'page', 'previous_page', 'stores'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stores['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 1\n",
      "next_page: None\n"
     ]
    }
   ],
   "source": [
    "print('max_page: %s' % data_stores['payload']['max_page'])\n",
    "print('next_page: %s' % data_stores['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'store_address': '12125 Alamo Ranch Pkwy',\n",
       "  'store_city': 'San Antonio',\n",
       "  'store_id': 1,\n",
       "  'store_state': 'TX',\n",
       "  'store_zipcode': '78253'},\n",
       " {'store_address': '9255 FM 471 West',\n",
       "  'store_city': 'San Antonio',\n",
       "  'store_id': 2,\n",
       "  'store_state': 'TX',\n",
       "  'store_zipcode': '78251'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stores['payload'].keys()\n",
    "data_stores['payload']['stores'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_state</th>\n",
       "      <th>store_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9255 FM 471 West</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>78251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2118 Fredericksburg Rdj</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>3</td>\n",
       "      <td>TX</td>\n",
       "      <td>78201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516 S Flores St</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>78204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1520 Austin Hwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>5</td>\n",
       "      <td>TX</td>\n",
       "      <td>78218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1015 S WW White Rd</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>6</td>\n",
       "      <td>TX</td>\n",
       "      <td>78220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12018 Perrin Beitel Rd</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>7</td>\n",
       "      <td>TX</td>\n",
       "      <td>78217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15000 San Pedro Ave</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>8</td>\n",
       "      <td>TX</td>\n",
       "      <td>78232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>735 SW Military Dr</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>9</td>\n",
       "      <td>TX</td>\n",
       "      <td>78221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8503 NW Military Hwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>10</td>\n",
       "      <td>TX</td>\n",
       "      <td>78231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             store_address   store_city  store_id store_state store_zipcode\n",
       "0   12125 Alamo Ranch Pkwy  San Antonio         1          TX         78253\n",
       "1         9255 FM 471 West  San Antonio         2          TX         78251\n",
       "2  2118 Fredericksburg Rdj  San Antonio         3          TX         78201\n",
       "3          516 S Flores St  San Antonio         4          TX         78204\n",
       "4          1520 Austin Hwy  San Antonio         5          TX         78218\n",
       "5       1015 S WW White Rd  San Antonio         6          TX         78220\n",
       "6   12018 Perrin Beitel Rd  San Antonio         7          TX         78217\n",
       "7      15000 San Pedro Ave  San Antonio         8          TX         78232\n",
       "8       735 SW Military Dr  San Antonio         9          TX         78221\n",
       "9     8503 NW Military Hwy  San Antonio        10          TX         78231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_df = pd.DataFrame(data_stores['payload']['stores'])\n",
    "print(stores_df.shape)\n",
    "stores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one page of store data, so I don't need to concatinate multiple pages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function:\n",
    "\n",
    "def get_stores_new(base_url):\n",
    "    '''\n",
    "    This function is designed to get the items data from Zach's web service and turn that data into a pandas\n",
    "    dataframe for use.\n",
    "    '''\n",
    "    \n",
    "    # initialize:\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['payload']['stores'])\n",
    "    \n",
    "    \n",
    "    if data['payload']['next_page'] == None:\n",
    "        return df\n",
    "    else:\n",
    "        for x in range(0, data['payload']['max_page']):\n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            df = pd.concat([df, pd.DataFrame(data['payload']['stores'])], ignore_index = True)\n",
    "        return df\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 5), (10, 5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_df_test = get_stores_new(base_url)\n",
    "stores_df.shape, stores_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Data\n",
    "\n",
    "### 3. Extract the data for sales. \n",
    "\n",
    "- There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_sales = 'https://python.zach.lol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function from what I'm doing here. While loop is based on next_page != \"None\"\n",
    "\n",
    "response_sales = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "\n",
    "data_sales = response_sales.json()\n",
    "data_sales.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sales['payload'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max_page: %s' % data_sales['payload']['max_page'])\n",
    "print('next_page: %s' % data_sales['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is looking at a set number of entries in the dictionary I'm calling from the api:\n",
    "data_sales['payload']['sales'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.DataFrame(data_sales['payload']['sales'])\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_sales = requests.get(base_url + data_sales['payload']['next_page'])\n",
    "data_sales = response_sales.json()\n",
    "\n",
    "print('max_page: %s' % data_sales['payload']['max_page'])\n",
    "print('next_page: %s' % data_sales['payload']['next_page'])\n",
    "\n",
    "sales_df = pd.concat([sales_df, pd.DataFrame(data_sales['payload']['sales'])]).reset_index()\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the same thing, but now I'm calling as many items are on the first page:\n",
    "len(data_sales['payload']['sales'])\n",
    "# There are 5000 items per page it seems. So the number of rows I'll have is:\n",
    "\n",
    "row_total_guess = len(data_sales['payload']['sales']) * (data_sales['payload']['max_page'])\n",
    "print(f'The estimated total number of rows of the combined sales dataframe is {row_total_guess:,}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales(base_url):\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "    data = response.json()\n",
    "    data.keys()\n",
    "    print('max_page: %s' % data['payload']['max_page'])\n",
    "    print('next_page: %s' % data['payload']['next_page'])\n",
    "    \n",
    "    df_sales = pd.DataFrame(data['payload']['sales'])\n",
    "    \n",
    "    while data['payload']['next_page'] != \"None\":\n",
    "        response = requests.get(base_url + data['payload']['next_page'])\n",
    "        data = response.json()\n",
    "        print('max_page: %s' % data['payload']['max_page'])\n",
    "        print('next_page: %s' % data['payload']['next_page'])\n",
    "        \n",
    "        \n",
    "        df_sales = pd.concat([df_sales, pd.DataFrame(data['payload']['sales'])])\n",
    "        \n",
    "        if data['payload']['next_page'] == None:\n",
    "            break\n",
    "            \n",
    "    df_sales = df_sales.reset_index()\n",
    "    print('full_shape', df_sales.shape)\n",
    "    return df_sales\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = get_sales(base_url_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a csv:\n",
    "\n",
    "def write_csv(df, csv_name):\n",
    "    '''\n",
    "    The first argument (df) is the dataframe you want written to a .csv file. \n",
    "    The second argument (csv_name) must be a string, including the .csv extention. eg: 'example_df.csv'\n",
    "    '''\n",
    "    \n",
    "    df.to_csv(csv_name, index = False)\n",
    "    print('Completed writing df to .csv file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(sales_df, 'sales_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(stores_df, 'stores_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(items, 'items_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales_df.shape)\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stores_df.shape)\n",
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items.shape)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, sales_df has both of the ids needed to join the two tables. I'll need to use two joins, both of them (I believe) will be a left join.\n",
    "\n",
    "sales_test = sales_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_test = items.copy()\n",
    "item_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.rename(columns = {'item_id': 'item'}, inplace = True)\n",
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.rename(columns = {'store_id': 'store'}, inplace = True)\n",
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merge = pd.merge(sales_df, items, how = 'left', on = 'item')\n",
    "left_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.merge(left_merge, stores_df, how = 'left', on = 'store')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv:\n",
    "\n",
    "write_csv(all_df, 'add_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Power System Data\n",
    "\n",
    "### 6. Acquire the Open Power Systems Data for Germany.\n",
    "\n",
    "- Which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "power_df = pd.read_csv(power_url, ',')\n",
    "power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit of prep work:\n",
    "\n",
    "power_df.rename(columns = {\"Date\": 'date', \"Consumption\": \"consumption\", \"Wind\": \"wind\", \"Solar\": \"solar\", \"Wind+Solar\": \"wind_solar\"}, inplace = True)\n",
    "power_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the function:\n",
    "\n",
    "def get_germany_power(power_url):\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(power_url, ',')\n",
    "    \n",
    "    # now the cleaning:\n",
    "    df.rename(columns = {\"Date\": 'date', \"Consumption\": \"consumption\", \"Wind\": \"wind\", \"Solar\": \"solar\", \"Wind+Solar\": \"wind_solar\"}, inplace = True)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the function..\n",
    "\n",
    "power_df_test = get_germany_power(power_url)\n",
    "power_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to a csv:\n",
    "\n",
    "write_csv(power_df_test, 'power_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Reproducibility\n",
    "\n",
    "### 7. Make sure all the work that you have done above is reproducible. \n",
    "- That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the items function:\n",
    "\n",
    "def get_items_data():\n",
    "    '''\n",
    "    This function is designed to get the items data from Zach's web service and turn that data into a pandas\n",
    "    dataframe for use.\n",
    "    '''\n",
    "    base_url = 'https://python.zach.lol'\n",
    "    \n",
    "    # initialize:\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['payload']['items'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in range(0, data['payload']['max_page']):\n",
    "        response = requests.get(base_url + data['payload']['next_page'])\n",
    "        data = response.json()\n",
    "        df = pd.concat([df, pd.DataFrame(data['payload']['items'])], ignore_index = True)\n",
    "        if data['payload']['next_page'] == None:\n",
    "            return df\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores function:\n",
    "\n",
    "def get_stores_list():\n",
    "    '''\n",
    "    This function is designed to get the items data from Zach's web service and turn that data into a pandas\n",
    "    dataframe for use.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    \n",
    "    # initialize:\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['payload']['stores'])\n",
    "    \n",
    "    \n",
    "    if data['payload']['next_page'] == None:\n",
    "        return df\n",
    "    else:\n",
    "        for x in range(0, data['payload']['max_page']):\n",
    "            response = requests.get(base_url + data['payload']['next_page'])\n",
    "            data = response.json()\n",
    "            df = pd.concat([df, pd.DataFrame(data['payload']['stores'])], ignore_index = True)\n",
    "        return df\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales function:\n",
    "# Thanks to Ryvyn and Corey for help!\n",
    "\n",
    "def get_sales_data():\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    \n",
    "    response = requests.get('https://python.zach.lol/api/v1/sales')\n",
    "    data = response.json()\n",
    "    data.keys()\n",
    "    print('max_page: %s' % data['payload']['max_page'])\n",
    "    print('next_page: %s' % data['payload']['next_page'])\n",
    "    \n",
    "    df_sales = pd.DataFrame(data['payload']['sales'])\n",
    "    \n",
    "    while data['payload']['next_page'] != \"None\":\n",
    "        response = requests.get(base_url + data['payload']['next_page'])\n",
    "        data = response.json()\n",
    "        print('max_page: %s' % data['payload']['max_page'])\n",
    "        print('next_page: %s' % data['payload']['next_page'])\n",
    "        \n",
    "        \n",
    "        df_sales = pd.concat([df_sales, pd.DataFrame(data['payload']['sales'])])\n",
    "        \n",
    "        if data['payload']['next_page'] == None:\n",
    "            break\n",
    "            \n",
    "    df_sales = df_sales.reset_index()\n",
    "    print('full_shape', df_sales.shape)\n",
    "    return df_sales\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining it all together:\n",
    "\n",
    "def get_store_data():\n",
    "    '''\n",
    "    This function will pull all the store, item and sales data from Zach's web service pages.\n",
    "    This function should be the basis of where to start the prep phase.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://python.zach.lol'\n",
    "    \n",
    "    # Calling the dataframes. I need to put in a cache = True argument somewhere so it doesn't always have to be \n",
    "    # pulling from Zach's web service. I think I can put that in here but I don't recall how that works.\n",
    "    \n",
    "    item_list = get_items_data()\n",
    "    print(item_list.shape)\n",
    "    store_list = get_stores_list()\n",
    "    print(store_list.shape)\n",
    "    sales_list = get_sales_data()\n",
    "    print(sales_list.shape)\n",
    "    \n",
    "    # renaming columns:\n",
    "    item_list.rename(columns = {'item_id': 'item'}, inplace = True)\n",
    "    store_list.rename(columns = {'store_id': 'store'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Merging the three dataframes:\n",
    "    left_merge = pd.merge(sales_list, item_list, how = 'left', on = 'item')\n",
    "    all_df = pd.merge(left_merge, store_list, how = 'left', on = 'store')\n",
    "    \n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting power data function:\n",
    "\n",
    "def get_germany_power():\n",
    "    \n",
    "    power_url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(power_url, ',')\n",
    "    \n",
    "    # now the cleaning:\n",
    "    df.rename(columns = {\"Date\": 'date', \"Consumption\": \"consumption\", \"Wind\": \"wind\", \"Solar\": \"solar\", \"Wind+Solar\": \"wind_solar\"}, inplace = True)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n",
      "(10, 5)\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=2\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=3\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=4\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=5\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=6\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=7\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=8\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=9\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=10\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=11\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=12\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=13\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=14\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=15\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=16\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=17\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=18\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=19\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=20\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=21\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=22\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=23\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=24\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=25\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=26\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=27\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=28\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=29\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=30\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=31\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=32\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=33\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=34\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=35\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=36\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=37\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=38\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=39\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=40\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=41\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=42\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=43\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=44\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=45\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=46\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=47\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=48\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=49\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=50\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=51\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=52\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=53\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=54\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=55\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=56\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=57\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=58\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=59\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=60\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=61\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=62\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=63\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=64\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=65\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=66\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=67\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=68\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=69\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=70\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=71\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=72\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=73\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=74\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=75\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=76\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=77\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=78\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=79\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=80\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=81\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=82\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=83\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=84\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=85\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=86\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=87\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=88\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=89\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=90\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=91\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=92\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=93\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=94\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=95\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=96\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=97\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=98\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=99\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=100\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=101\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=102\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=103\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=104\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=105\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=106\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=107\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=108\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=109\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=110\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=111\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=112\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=113\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=114\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=115\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=116\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=117\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=118\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=119\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=120\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=121\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=122\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=123\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=124\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=125\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=126\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=127\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=128\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=129\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=130\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=131\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=132\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=133\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=134\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=135\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=136\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=137\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=138\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=139\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=140\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=141\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=142\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=143\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=144\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=145\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=146\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=147\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=148\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=149\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=150\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=151\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=152\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=153\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=154\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=155\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=156\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=157\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=158\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=159\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=160\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=161\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=162\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=163\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=164\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=165\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=166\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=167\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=168\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=169\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=170\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=171\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=172\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=173\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=175\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=176\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=177\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=178\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=179\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=180\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=181\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=182\n",
      "max_page: 183\n",
      "next_page: /api/v1/sales?page=183\n",
      "max_page: 183\n",
      "next_page: None\n",
      "full_shape (913000, 6)\n",
      "(913000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(913000, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_test = get_store_data()\n",
    "df_all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
